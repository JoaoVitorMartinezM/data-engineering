[2025-11-24T19:03:58.379+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_spark_working.validate_silver_data scheduled__2025-11-23T00:00:00+00:00 [queued]>
[2025-11-24T19:03:58.387+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_spark_working.validate_silver_data scheduled__2025-11-23T00:00:00+00:00 [queued]>
[2025-11-24T19:03:58.387+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 3
[2025-11-24T19:03:58.399+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): validate_silver_data> on 2025-11-23 00:00:00+00:00
[2025-11-24T19:03:58.404+0000] {standard_task_runner.py:60} INFO - Started process 1924 to run task
[2025-11-24T19:03:58.406+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'etl_spark_working', 'validate_silver_data', 'scheduled__2025-11-23T00:00:00+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/etl_spark_working_dag.py', '--cfg-path', '/tmp/tmp0qw2s_6g']
[2025-11-24T19:03:58.409+0000] {standard_task_runner.py:88} INFO - Job 34: Subtask validate_silver_data
[2025-11-24T19:03:58.471+0000] {task_command.py:423} INFO - Running <TaskInstance: etl_spark_working.validate_silver_data scheduled__2025-11-23T00:00:00+00:00 [running]> on host 7934b6c65b02
[2025-11-24T19:03:58.570+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-engineer' AIRFLOW_CTX_DAG_ID='etl_spark_working' AIRFLOW_CTX_TASK_ID='validate_silver_data' AIRFLOW_CTX_EXECUTION_DATE='2025-11-23T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-11-23T00:00:00+00:00'
[2025-11-24T19:03:58.571+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-11-24T19:03:58.573+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', '\n    echo "üîç ========== VALIDANDO SILVER LAYER =========="\n    \n    echo "Verificando processamento silver..."\n    \n    if docker exec spark_master ls -la /opt/spark/work-dir/ 2>/dev/null; then\n        echo "‚úÖ Workspace do Spark acess√≠vel"\n    fi\n    \n    echo "‚úÖ Valida√ß√£o do Silver Layer conclu√≠da"\n    echo "============================================"\n    ']
[2025-11-24T19:03:58.583+0000] {subprocess.py:86} INFO - Output:
[2025-11-24T19:03:58.586+0000] {subprocess.py:93} INFO - üîç ========== VALIDANDO SILVER LAYER ==========
[2025-11-24T19:03:58.587+0000] {subprocess.py:93} INFO - Verificando processamento silver...
[2025-11-24T19:03:58.717+0000] {subprocess.py:93} INFO - total 28
[2025-11-24T19:03:58.718+0000] {subprocess.py:93} INFO - drwxrwxrwx 1 root  root  4096 Nov 24 17:41 .
[2025-11-24T19:03:58.719+0000] {subprocess.py:93} INFO - drwxr-xr-x 1 spark spark 4096 Nov 14 00:40 ..
[2025-11-24T19:03:58.720+0000] {subprocess.py:93} INFO - -rwxrwxrwx 1 root  root  2616 Nov 24 13:55 bronze_script.py
[2025-11-24T19:03:58.721+0000] {subprocess.py:93} INFO - drwxrwxrwx 1 root  root  4096 Nov 24 18:23 data
[2025-11-24T19:03:58.721+0000] {subprocess.py:93} INFO - -rwxrwxrwx 1 root  root  2096 Nov 21 14:17 delta_timetravel.py
[2025-11-24T19:03:58.722+0000] {subprocess.py:93} INFO - -rwxrwxrwx 1 root  root  2139 Nov 21 14:17 delta_timetravel_simple.py
[2025-11-24T19:03:58.722+0000] {subprocess.py:93} INFO - -rwxrwxrwx 1 root  root  1492 Nov 24 14:33 gold_script.py
[2025-11-24T19:03:58.723+0000] {subprocess.py:93} INFO - -rwxrwxrwx 1 root  root  1490 Nov 24 17:26 quality_check.py
[2025-11-24T19:03:58.724+0000] {subprocess.py:93} INFO - -rwxrwxrwx 1 root  root  1596 Nov 24 14:24 silver_script.py
[2025-11-24T19:03:58.724+0000] {subprocess.py:93} INFO - ‚úÖ Workspace do Spark acess√≠vel
[2025-11-24T19:03:58.724+0000] {subprocess.py:93} INFO - ‚úÖ Valida√ß√£o do Silver Layer conclu√≠da
[2025-11-24T19:03:58.724+0000] {subprocess.py:93} INFO - ============================================
[2025-11-24T19:03:58.725+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-11-24T19:03:58.755+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=etl_spark_working, task_id=validate_silver_data, execution_date=20251123T000000, start_date=20251124T190358, end_date=20251124T190358
[2025-11-24T19:03:58.780+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-11-24T19:03:58.809+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
