[2025-11-24T19:05:32.081+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_spark_working.validate_silver_data manual__2025-11-24T19:03:02+00:00 [queued]>
[2025-11-24T19:05:32.092+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_spark_working.validate_silver_data manual__2025-11-24T19:03:02+00:00 [queued]>
[2025-11-24T19:05:32.093+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 3
[2025-11-24T19:05:32.106+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): validate_silver_data> on 2025-11-24 19:03:02+00:00
[2025-11-24T19:05:32.110+0000] {standard_task_runner.py:60} INFO - Started process 2095 to run task
[2025-11-24T19:05:32.113+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'etl_spark_working', 'validate_silver_data', 'manual__2025-11-24T19:03:02+00:00', '--job-id', '41', '--raw', '--subdir', 'DAGS_FOLDER/etl_spark_working_dag.py', '--cfg-path', '/tmp/tmp1wwpb4f8']
[2025-11-24T19:05:32.116+0000] {standard_task_runner.py:88} INFO - Job 41: Subtask validate_silver_data
[2025-11-24T19:05:32.183+0000] {task_command.py:423} INFO - Running <TaskInstance: etl_spark_working.validate_silver_data manual__2025-11-24T19:03:02+00:00 [running]> on host 7934b6c65b02
[2025-11-24T19:05:32.278+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-engineer' AIRFLOW_CTX_DAG_ID='etl_spark_working' AIRFLOW_CTX_TASK_ID='validate_silver_data' AIRFLOW_CTX_EXECUTION_DATE='2025-11-24T19:03:02+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-11-24T19:03:02+00:00'
[2025-11-24T19:05:32.279+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-11-24T19:05:32.281+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', '\n    echo "üîç ========== VALIDANDO SILVER LAYER =========="\n    \n    echo "Verificando processamento silver..."\n    \n    if docker exec spark_master ls -la /opt/spark/work-dir/ 2>/dev/null; then\n        echo "‚úÖ Workspace do Spark acess√≠vel"\n    fi\n    \n    echo "‚úÖ Valida√ß√£o do Silver Layer conclu√≠da"\n    echo "============================================"\n    ']
[2025-11-24T19:05:32.289+0000] {subprocess.py:86} INFO - Output:
[2025-11-24T19:05:32.291+0000] {subprocess.py:93} INFO - üîç ========== VALIDANDO SILVER LAYER ==========
[2025-11-24T19:05:32.292+0000] {subprocess.py:93} INFO - Verificando processamento silver...
[2025-11-24T19:05:32.387+0000] {subprocess.py:93} INFO - total 28
[2025-11-24T19:05:32.388+0000] {subprocess.py:93} INFO - drwxrwxrwx 1 root  root  4096 Nov 24 17:41 .
[2025-11-24T19:05:32.389+0000] {subprocess.py:93} INFO - drwxr-xr-x 1 spark spark 4096 Nov 14 00:40 ..
[2025-11-24T19:05:32.389+0000] {subprocess.py:93} INFO - -rwxrwxrwx 1 root  root  2616 Nov 24 13:55 bronze_script.py
[2025-11-24T19:05:32.390+0000] {subprocess.py:93} INFO - drwxrwxrwx 1 root  root  4096 Nov 24 18:23 data
[2025-11-24T19:05:32.391+0000] {subprocess.py:93} INFO - -rwxrwxrwx 1 root  root  2096 Nov 21 14:17 delta_timetravel.py
[2025-11-24T19:05:32.391+0000] {subprocess.py:93} INFO - -rwxrwxrwx 1 root  root  2139 Nov 21 14:17 delta_timetravel_simple.py
[2025-11-24T19:05:32.392+0000] {subprocess.py:93} INFO - -rwxrwxrwx 1 root  root  1492 Nov 24 14:33 gold_script.py
[2025-11-24T19:05:32.392+0000] {subprocess.py:93} INFO - -rwxrwxrwx 1 root  root  1490 Nov 24 17:26 quality_check.py
[2025-11-24T19:05:32.392+0000] {subprocess.py:93} INFO - -rwxrwxrwx 1 root  root  1596 Nov 24 14:24 silver_script.py
[2025-11-24T19:05:32.393+0000] {subprocess.py:93} INFO - ‚úÖ Workspace do Spark acess√≠vel
[2025-11-24T19:05:32.393+0000] {subprocess.py:93} INFO - ‚úÖ Valida√ß√£o do Silver Layer conclu√≠da
[2025-11-24T19:05:32.394+0000] {subprocess.py:93} INFO - ============================================
[2025-11-24T19:05:32.394+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-11-24T19:05:32.423+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=etl_spark_working, task_id=validate_silver_data, execution_date=20251124T190302, start_date=20251124T190532, end_date=20251124T190532
[2025-11-24T19:05:32.447+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-11-24T19:05:32.474+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
